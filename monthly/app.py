# app.py
import streamlit as st
import tempfile
from pathlib import Path
import re
import xarray as xr
import rioxarray as rxr
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import warnings
import datetime

warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'STHeiti']
matplotlib.rcParams['axes.unicode_minus'] = False

from utils.analysis_tools import (
    theil_sen_trend,
    mann_kendall_test,
    bfast_detection,
    fft_analysis,
    stl_decompose_pixelwise
)
from utils.visualization import (
    plot_map,
    plot_pixel_timeseries,
    dataarray_to_bytes_tif,
    fig_to_bytes_png
)

# ==================== ä¸­æ–‡å­—ä½“é…ç½® ====================

# ==================== ä¸­æ–‡å­—ä½“é…ç½® (ä¼˜åŒ–ç‰ˆï¼Œé€‚ç”¨äºäº‘ç«¯éƒ¨ç½²) ====================

def configure_chinese_fonts():
    """
    é…ç½®matplotlibä¸­æ–‡å­—ä½“ï¼Œä¼˜å…ˆä½¿ç”¨é¡¹ç›®å†…ç½®å­—ä½“æ–‡ä»¶ï¼Œç¡®ä¿äº‘ç«¯éƒ¨ç½²æ—¶ä¸­æ–‡æ­£å¸¸æ˜¾ç¤º
    """
    import platform
    from matplotlib.font_manager import fontManager, FontProperties
    import os

    # ===== ç­–ç•¥1ï¼šä¼˜å…ˆåŠ è½½é¡¹ç›®å†…ç½®å­—ä½“ï¼ˆé€‚ç”¨äºéƒ¨ç½²ç¯å¢ƒï¼‰ =====
    font_filename = 'SIMSUN.TTC'
    font_path = os.path.join('fonts', font_filename)

    if os.path.exists(font_path):
        try:
            # åŠ¨æ€æ³¨å†Œå­—ä½“åˆ°matplotlib
            fontManager.addfont(font_path)

            # è·å–å­—ä½“çš„å®é™…åç§°
            prop = FontProperties(fname=font_path)
            font_name = prop.get_name()  # é€šå¸¸æ˜¯ 'Source Han Sans SC'

            # è®¾ç½®ä¸ºmatplotlibçš„é»˜è®¤å­—ä½“
            plt.rcParams['font.sans-serif'] = [font_name]
            plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜

            return True, font_name
        except Exception as e:
            print(f"âš ï¸ åŠ è½½å†…ç½®å­—ä½“å¤±è´¥: {e}")
    else:
        print(f"âš ï¸ æœªæ‰¾åˆ°å­—ä½“æ–‡ä»¶: {font_path}")

    # ===== ç­–ç•¥2ï¼šå›é€€åˆ°ç³»ç»Ÿå­—ä½“ï¼ˆé€‚ç”¨äºæœ¬åœ°å¼€å‘ï¼‰ =====
    system = platform.system()
    chinese_fonts = []

    if system == 'Windows':
        chinese_fonts = ['SimHei', 'Microsoft YaHei', 'SimSun']
    elif system == 'Darwin':  # macOS
        chinese_fonts = ['PingFang SC', 'Heiti SC', 'STHeiti']
    else:  # Linux
        chinese_fonts = ['WenQuanYi Micro Hei', 'WenQuanYi Zen Hei', 'Droid Sans Fallback']

    from matplotlib.font_manager import FontManager
    fm = FontManager()
    available_fonts = {f.name for f in fm.ttflist}

    selected_font = None
    for font in chinese_fonts:
        if font in available_fonts:
            selected_font = font
            break

    # å¦‚æœä»ç„¶æ‰¾ä¸åˆ°ï¼Œå°è¯•æœç´¢åŒ…å«ä¸­æ–‡å…³é”®è¯çš„å­—ä½“
    if selected_font is None:
        for font in available_fonts:
            if any(keyword in font.lower() for keyword in ['chinese', 'cjk', 'han', 'hei', 'song']):
                selected_font = font
                break

    if selected_font:
        plt.rcParams['font.sans-serif'] = [selected_font]
        plt.rcParams['axes.unicode_minus'] = False
        return True, selected_font
    else:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•å¯ç”¨çš„ä¸­æ–‡å­—ä½“")
        return False, None


# æ‰§è¡Œå­—ä½“é…ç½®
CHINESE_SUPPORT, SELECTED_FONT = configure_chinese_fonts()

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ—¶åºé¥æ„Ÿåˆ†æç³»ç»Ÿ",
    layout="wide",
    page_icon="ğŸ›°ï¸"
)

st.title("ğŸ›°ï¸ æ—¶åºé¥æ„Ÿåˆ†æç³»ç»Ÿ")
st.markdown("""
**åŠŸèƒ½æ¨¡å—ï¼š** Theilâ€“Senè¶‹åŠ¿åˆ†æ | Mannâ€“Kendallæ£€éªŒ | BFASTçªå˜æ£€æµ‹ | FFTå‘¨æœŸåˆ†æ | STLåˆ†è§£
""")


# ---------------------------
# æ–‡ä»¶ä¸Šä¼ ä¸é¢„å¤„ç†
# ---------------------------
@st.cache_data(show_spinner=False)
def extract_time(filename):
    """
    ä»æ–‡ä»¶åä¸­æå–æ—¶é—´ä¿¡æ¯ï¼Œæ”¯æŒå¤šç§æ ¼å¼
    è¿”å› datetime å¯¹è±¡
    """
    # å°è¯•åŒ¹é… YYYY_DDD æ ¼å¼ (2020_001, 2020_365)
    m = re.search(r'(19\d{2}|20\d{2})_(\d{3})', filename)
    if m:
        year = int(m.group(1))
        day_of_year = int(m.group(2))
        # å°†ä¸€å¹´ä¸­çš„ç¬¬å‡ å¤©è½¬æ¢ä¸ºæœˆä»½å’Œæ—¥æœŸ
        try:
            date = datetime.datetime(year, 1, 1) + datetime.timedelta(days=day_of_year - 1)
            return date
        except:
            return datetime.datetime(year, 1, 1)

    # å°è¯•åŒ¹é… YYYY_MM æ ¼å¼ (2020_01, 2020_12)
    m = re.search(r'(19\d{2}|20\d{2})_(\d{1,2})', filename)
    if m:
        year = int(m.group(1))
        month = int(m.group(2))
        return datetime.datetime(year, month, 1)

    # å°è¯•åŒ¹é… YYYYMM æ ¼å¼ (202001, 202012)
    m = re.search(r'(19\d{2}|20\d{2})(\d{2})', filename)
    if m:
        year = int(m.group(1))
        month = int(m.group(2))
        return datetime.datetime(year, month, 1)

    # å°è¯•åŒ¹é… YYYY æ ¼å¼ (2000, 2001)
    m = re.search(r'(19\d{2}|20\d{2})', filename)
    if m:
        year = int(m.group(0))
        return datetime.datetime(year, 1, 1)  # å¹´åº¦æ•°æ®é»˜è®¤è®¾ä¸º1æœˆ1æ—¥

    # å°è¯•åŒ¹é…è‹±æ–‡æœˆä»½
    month_map = {
        'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6,
        'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12
    }

    for month_name, month_num in month_map.items():
        if month_name in filename:
            m = re.search(r'(19\d{2}|20\d{2})', filename)
            if m:
                year = int(m.group(0))
                return datetime.datetime(year, month_num, 1)

    return None


@st.cache_data(show_spinner=False)
def load_and_stack_files(_uploaded_files):
    """åŠ è½½å¹¶å †å æ–‡ä»¶ - ä¿®å¤æ—¶é—´åæ ‡é—®é¢˜"""
    tmpdir = Path(tempfile.mkdtemp())
    paths = []

    for f in _uploaded_files:
        p = tmpdir / f.name
        p.write_bytes(f.getbuffer())
        paths.append(p)

    # æå–æ—¶é—´ä¿¡æ¯
    times = [extract_time(f.name) for f in _uploaded_files]

    # æ˜¾ç¤ºæ–‡ä»¶åå’Œæ—¶é—´æå–ç»“æœç”¨äºè°ƒè¯•
    st.info("æ–‡ä»¶åå’Œæ—¶é—´æå–ç»“æœ:")
    for f, t in zip(_uploaded_files, times):
        if t:
            st.write(f"- {f.name} -> {t}")
        else:
            st.write(f"- {f.name} -> æ— æ³•æå–æ—¶é—´")

    # æ£€æŸ¥æ—¶é—´æå–
    invalid_files = [(f.name, t) for f, t in zip(_uploaded_files, times) if t is None]
    if invalid_files:
        st.error("ä»¥ä¸‹æ–‡ä»¶ä¸­æœªæ£€æµ‹åˆ°æœ‰æ•ˆæ—¶é—´ä¿¡æ¯:")
        for fname, time_val in invalid_files:
            st.error(f"  - {fname}")
        st.info("ğŸ’¡ æ”¯æŒçš„æ–‡ä»¶åæ ¼å¼:")
        st.info("   - å¹´åº¦æ•°æ®: NDVI_2000.tif, NDVI_2001_å¾å·.tif")
        st.info("   - æœˆåº¦æ•°æ®: NDVI_200001.tif, NDVI_2000_01.tif, NDVI_2000_01_å¾å·.tif")
        st.info("   - æ—¥åº¦æ•°æ®: NDVI_2000_001.tif, NDVI_2000_365_å¾å·.tif")
        return None

    # æŒ‰æ—¶é—´æ’åºå¹¶æ£€æŸ¥é‡å¤
    sorted_indices = sorted(range(len(times)), key=lambda i: times[i])
    paths = [paths[i] for i in sorted_indices]
    times = [times[i] for i in sorted_indices]
    _uploaded_files = [_uploaded_files[i] for i in sorted_indices]

    # æ£€æŸ¥æ—¶é—´é‡å¤å¹¶æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    time_count = {}
    duplicate_files = {}
    for f, t in zip(_uploaded_files, times):
        if t not in time_count:
            time_count[t] = []
        time_count[t].append(f.name)

    duplicate_times = [t for t, files in time_count.items() if len(files) > 1]

    if duplicate_times:
        st.warning("âš ï¸ æ£€æµ‹åˆ°é‡å¤çš„æ—¶é—´ç‚¹:")
        for t in duplicate_times:
            st.error(f"æ—¶é—´ {t.strftime('%Y-%m-%d')} å¯¹åº”çš„æ–‡ä»¶:")
            for fname in time_count[t]:
                st.error(f"  - {fname}")
        st.info("æ—¶åºåˆ†æè¦æ±‚æ¯ä¸ªæ—¶é—´ç‚¹åªæœ‰ä¸€ä¸ªè§‚æµ‹å€¼ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶å‘½åã€‚")

        # è¯¢é—®ç”¨æˆ·æ˜¯å¦ç»§ç»­
        continue_anyway = st.checkbox("å¿½ç•¥é‡å¤æ—¶é—´ç‚¹ï¼Œç»§ç»­åˆ†æ", value=False)
        if not continue_anyway:
            return None

    # è¯»å–æ•°æ®
    data_list = []
    time_coords = []
    for p, t in zip(paths, times):
        try:
            da = rxr.open_rasterio(str(p), chunks={'x': 512, 'y': 512}).squeeze()
            if "band" in da.dims:
                da = da.isel(band=0).drop_vars('band')

            # ç¡®ä¿æ•°æ®æ˜¯2Dçš„ (y, x)
            if da.ndim != 2:
                st.error(f"æ–‡ä»¶ {p.name} çš„ç»´åº¦ä¸æ­£ç¡®ï¼ŒæœŸæœ›2Dæ•°æ® (y, x)ï¼Œå®é™…ç»´åº¦: {da.dims}")
                continue

            data_list.append(da)
            time_coords.append(t)

        except Exception as e:
            st.error(f"è¯»å–æ–‡ä»¶ {p.name} æ—¶å‡ºé”™: {e}")
            continue

    if not data_list:
        st.error("æ²¡æœ‰æˆåŠŸè¯»å–ä»»ä½•æ–‡ä»¶")
        return None

    # å †å æ•°æ®
    try:
        # ä½¿ç”¨concatè€Œä¸æ˜¯expand_dimsï¼Œç¡®ä¿æ—¶é—´ç»´åº¦æ­£ç¡®
        stack = xr.concat(data_list, dim="time")
        stack = stack.assign_coords(time=time_coords)
        stack = stack.transpose('time', 'y', 'x')

        # éªŒè¯æ•°æ®å½¢çŠ¶
        st.info(f"æ•°æ®æ ˆå½¢çŠ¶: {stack.shape} (æ—¶é—´, Y, X)")

        # æ˜¾ç¤ºæ—¶é—´åæ ‡ä¿¡æ¯
        time_info = []
        for t in stack.time.values:
            if isinstance(t, np.datetime64):
                time_info.append(np.datetime_as_string(t, unit='D'))
            else:
                time_info.append(str(t))
        st.info(f"æ—¶é—´åæ ‡: {time_info}")

        return stack

    except Exception as e:
        st.error(f"æ•°æ®å †å å¤±è´¥: {e}")
        return None

@st.cache_data(show_spinner=False)
def load_and_stack_files(_uploaded_files):
    """åŠ è½½å¹¶å †å æ–‡ä»¶ - ä¿®å¤æ—¶é—´åæ ‡é—®é¢˜"""
    tmpdir = Path(tempfile.mkdtemp())
    paths = []

    for f in _uploaded_files:
        p = tmpdir / f.name
        p.write_bytes(f.getbuffer())
        paths.append(p)

    # æå–æ—¶é—´ä¿¡æ¯
    times = [extract_time(f.name) for f in _uploaded_files]

    # æ£€æŸ¥æ—¶é—´æå–
    invalid_files = [(f.name, t) for f, t in zip(_uploaded_files, times) if t is None]
    if invalid_files:
        st.error("ä»¥ä¸‹æ–‡ä»¶ä¸­æœªæ£€æµ‹åˆ°æœ‰æ•ˆæ—¶é—´ä¿¡æ¯:")
        for fname, time_val in invalid_files:
            st.error(f"  - {fname}")
        st.info("ğŸ’¡ æ”¯æŒçš„æ–‡ä»¶åæ ¼å¼:")
        st.info("   - å¹´åº¦æ•°æ®: NDVI_2000.tif, NDVI_2001_å¾å·.tif")
        st.info("   - æœˆåº¦æ•°æ®: NDVI_200001.tif, NDVI_2000_01.tif, NDVI_2000_01_å¾å·.tif")
        st.info("   - æ—¥åº¦æ•°æ®: NDVI_2000_001.tif, NDVI_2000_365_å¾å·.tif")
        return None

    # æŒ‰æ—¶é—´æ’åºå¹¶æ£€æŸ¥é‡å¤
    sorted_indices = sorted(range(len(times)), key=lambda i: times[i])
    paths = [paths[i] for i in sorted_indices]
    times = [times[i] for i in sorted_indices]
    _uploaded_files = [_uploaded_files[i] for i in sorted_indices]

    # æ£€æŸ¥æ—¶é—´é‡å¤å¹¶æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    time_count = {}
    duplicate_files = {}
    for f, t in zip(_uploaded_files, times):
        if t not in time_count:
            time_count[t] = []
        time_count[t].append(f.name)

    duplicate_times = [t for t, files in time_count.items() if len(files) > 1]

    if duplicate_times:
        st.warning("âš ï¸ æ£€æµ‹åˆ°é‡å¤çš„æ—¶é—´ç‚¹:")
        for t in duplicate_times:
            st.error(f"æ—¶é—´ {t.strftime('%Y-%m-%d')} å¯¹åº”çš„æ–‡ä»¶:")
            for fname in time_count[t]:
                st.error(f"  - {fname}")
        st.info("æ—¶åºåˆ†æè¦æ±‚æ¯ä¸ªæ—¶é—´ç‚¹åªæœ‰ä¸€ä¸ªè§‚æµ‹å€¼ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶å‘½åã€‚")

        # è¯¢é—®ç”¨æˆ·æ˜¯å¦ç»§ç»­
        continue_anyway = st.checkbox("å¿½ç•¥é‡å¤æ—¶é—´ç‚¹ï¼Œç»§ç»­åˆ†æ", value=False)
        if not continue_anyway:
            return None

    # è¯»å–æ•°æ®
    data_list = []
    time_coords = []
    for p, t in zip(paths, times):
        try:
            da = rxr.open_rasterio(str(p), chunks={'x': 512, 'y': 512}).squeeze()
            if "band" in da.dims:
                da = da.isel(band=0).drop_vars('band')

            # ç¡®ä¿æ•°æ®æ˜¯2Dçš„ (y, x)
            if da.ndim != 2:
                st.error(f"æ–‡ä»¶ {p.name} çš„ç»´åº¦ä¸æ­£ç¡®ï¼ŒæœŸæœ›2Dæ•°æ® (y, x)ï¼Œå®é™…ç»´åº¦: {da.dims}")
                continue

            data_list.append(da)
            time_coords.append(t)

        except Exception as e:
            st.error(f"è¯»å–æ–‡ä»¶ {p.name} æ—¶å‡ºé”™: {e}")
            continue

    if not data_list:
        st.error("æ²¡æœ‰æˆåŠŸè¯»å–ä»»ä½•æ–‡ä»¶")
        return None

    # å †å æ•°æ®
    try:
        # ä½¿ç”¨concatè€Œä¸æ˜¯expand_dimsï¼Œç¡®ä¿æ—¶é—´ç»´åº¦æ­£ç¡®
        stack = xr.concat(data_list, dim="time")
        stack = stack.assign_coords(time=time_coords)
        stack = stack.transpose('time', 'y', 'x')

        # éªŒè¯æ•°æ®å½¢çŠ¶
        st.info(f"æ•°æ®æ ˆå½¢çŠ¶: {stack.shape} (æ—¶é—´, Y, X)")

        # æ˜¾ç¤ºæ—¶é—´åæ ‡ä¿¡æ¯
        time_info = []
        for t in stack.time.values:
            if isinstance(t, np.datetime64):
                time_info.append(np.datetime_as_string(t, unit='D'))
            else:
                time_info.append(str(t))
        st.info(f"æ—¶é—´åæ ‡: {time_info}")

        return stack

    except Exception as e:
        st.error(f"æ•°æ®å †å å¤±è´¥: {e}")
        return None

@st.cache_data(show_spinner=False)
def load_and_stack_files(_uploaded_files):
    """åŠ è½½å¹¶å †å æ–‡ä»¶ - ä¿®å¤æ—¶é—´åæ ‡é—®é¢˜"""
    tmpdir = Path(tempfile.mkdtemp())
    paths = []

    for f in _uploaded_files:
        p = tmpdir / f.name
        p.write_bytes(f.getbuffer())
        paths.append(p)

    # æå–æ—¶é—´ä¿¡æ¯
    times = [extract_time(f.name) for f in _uploaded_files]

    # æ£€æŸ¥æ—¶é—´æå–
    invalid_files = [(f.name, t) for f, t in zip(_uploaded_files, times) if t is None]
    if invalid_files:
        st.error("ä»¥ä¸‹æ–‡ä»¶ä¸­æœªæ£€æµ‹åˆ°æœ‰æ•ˆæ—¶é—´ä¿¡æ¯:")
        for fname, time_val in invalid_files:
            st.error(f"  - {fname}")
        st.info("ğŸ’¡ è¯·ç¡®ä¿æ–‡ä»¶ååŒ…å«4ä½å¹´ä»½ï¼Œå¦‚: 2000, 1999 æˆ– 200001, 200012")
        return None

    # æŒ‰æ—¶é—´æ’åºå¹¶æ£€æŸ¥é‡å¤
    sorted_indices = sorted(range(len(times)), key=lambda i: times[i])
    paths = [paths[i] for i in sorted_indices]
    times = [times[i] for i in sorted_indices]
    _uploaded_files = [_uploaded_files[i] for i in sorted_indices]

    # æ£€æŸ¥æ—¶é—´é‡å¤
    unique_times = set()
    duplicate_times = []
    for t in times:
        if t in unique_times:
            duplicate_times.append(t)
        else:
            unique_times.add(t)

    if duplicate_times:
        st.warning(f"âš ï¸ æ£€æµ‹åˆ°é‡å¤çš„æ—¶é—´ç‚¹: {duplicate_times}")
        st.info("æ—¶åºåˆ†æè¦æ±‚æ¯ä¸ªæ—¶é—´ç‚¹åªæœ‰ä¸€ä¸ªè§‚æµ‹å€¼ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶å‘½åã€‚")

    # è¯»å–æ•°æ®
    data_list = []
    time_coords = []
    for p, t in zip(paths, times):
        try:
            da = rxr.open_rasterio(str(p), chunks={'x': 512, 'y': 512}).squeeze()
            if "band" in da.dims:
                da = da.isel(band=0).drop_vars('band')

            # ç¡®ä¿æ•°æ®æ˜¯2Dçš„ (y, x)
            if da.ndim != 2:
                st.error(f"æ–‡ä»¶ {p.name} çš„ç»´åº¦ä¸æ­£ç¡®ï¼ŒæœŸæœ›2Dæ•°æ® (y, x)ï¼Œå®é™…ç»´åº¦: {da.dims}")
                continue

            data_list.append(da)
            time_coords.append(t)

        except Exception as e:
            st.error(f"è¯»å–æ–‡ä»¶ {p.name} æ—¶å‡ºé”™: {e}")
            continue

    if not data_list:
        st.error("æ²¡æœ‰æˆåŠŸè¯»å–ä»»ä½•æ–‡ä»¶")
        return None

    # å †å æ•°æ®
    try:
        # ä½¿ç”¨concatè€Œä¸æ˜¯expand_dimsï¼Œç¡®ä¿æ—¶é—´ç»´åº¦æ­£ç¡®
        stack = xr.concat(data_list, dim="time")
        stack = stack.assign_coords(time=time_coords)
        stack = stack.transpose('time', 'y', 'x')

        # éªŒè¯æ•°æ®å½¢çŠ¶
        st.info(f"æ•°æ®æ ˆå½¢çŠ¶: {stack.shape} (æ—¶é—´, Y, X)")
        st.info(f"æ—¶é—´åæ ‡: {stack.time.values}")

        return stack

    except Exception as e:
        st.error(f"æ•°æ®å †å å¤±è´¥: {e}")
        return None


# åˆå§‹åŒ–session state
if 'analysis_results' not in st.session_state:
    st.session_state.analysis_results = {}
if 'data_stack' not in st.session_state:
    st.session_state.data_stack = None

# æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
st.sidebar.header("ğŸ“ æ•°æ®ä¸Šä¼ ")
uploaded_files = st.sidebar.file_uploader(
    "ä¸Šä¼ å¤šæœŸ GeoTIFF æ–‡ä»¶",
    type=["tif", "tiff"],
    accept_multiple_files=True,
    help="æ–‡ä»¶ååº”åŒ…å«å¹´ä»½ï¼Œå¦‚: NDVI_2000.tif (å¹´åº¦) æˆ– NDVI_200001.tif (æœˆåº¦)"
)

if uploaded_files:
    # æŒ‰æ–‡ä»¶åæ’åºä»¥ç¡®ä¿ä¸€è‡´æ€§
    uploaded_files = sorted(uploaded_files, key=lambda f: f.name)

    # åŠ è½½æ•°æ®
    with st.spinner("ğŸ”„ æ­£åœ¨åŠ è½½å’Œå¤„ç†æ …æ ¼æ•°æ®..."):
        data_stack = load_and_stack_files(uploaded_files)

    if data_stack is not None:
        st.session_state.data_stack = data_stack

        # æ£€æµ‹æ•°æ®ç±»å‹å¹¶æ˜¾ç¤ºä¿¡æ¯
        times = data_stack.time.values
        time_labels = []
        for t in times:
            if isinstance(t, np.datetime64):
                time_labels.append(np.datetime_as_string(t, unit='D'))
            else:
                time_labels.append(str(t))

        # åˆ¤æ–­æ•°æ®é¢‘ç‡
        data_frequency = "å¹´åº¦æ•°æ®"
        if len(times) > 1:
            if isinstance(times[0], np.datetime64):
                time_diff = times[1] - times[0]
                days_diff = time_diff / np.timedelta64(1, 'D')
                if 28 <= days_diff <= 31:
                    data_frequency = "æœˆåº¦æ•°æ®"
                elif 360 <= days_diff <= 370:
                    data_frequency = "å¹´åº¦æ•°æ®"

        # æ˜¾ç¤ºæ•°æ®ä¿¡æ¯
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("æ•°æ®é¢‘ç‡", data_frequency)
        with col2:
            st.metric("æ—¶é—´åºåˆ—é•¿åº¦", f"{data_stack.sizes['time']} æœŸ")
        with col3:
            st.metric("ç©ºé—´åˆ†è¾¨ç‡", f"{data_stack.sizes['y']} Ã— {data_stack.sizes['x']}")
        with col4:
            if len(time_labels) > 0:
                st.metric("æ—¶é—´èŒƒå›´", f"{time_labels[0]} è‡³ {time_labels[-1]}")

        # æ•°æ®é¢„è§ˆ
        with st.expander("ğŸ“Š æ•°æ®é¢„è§ˆ", expanded=True):
            tab1, tab2, tab3 = st.tabs(["ç©ºé—´åˆ†å¸ƒ", "æ—¶é—´åºåˆ—æŠ½æ ·", "ç»Ÿè®¡ä¿¡æ¯"])

            with tab1:
                st.subheader("ç¬¬ä¸€æœŸæ …æ ¼é¢„è§ˆ")
                plot_map(data_stack.isel(time=0),
                         title=f"æ—¶é—´: {time_labels[0]}")

            with tab2:
                st.subheader("éšæœºåƒå…ƒæ—¶é—´åºåˆ—æŠ½æ ·")
                # éšæœºé€‰æ‹©å‡ ä¸ªåƒå…ƒæ˜¾ç¤ºæ—¶é—´åºåˆ—
                ny, nx = data_stack.sizes['y'], data_stack.sizes['x']
                if ny > 0 and nx > 0:
                    # éšæœºé€‰æ‹©å‡ ä¸ªä½ç½®
                    import random

                    fig, axes = plt.subplots(2, 2, figsize=(12, 8))
                    axes = axes.flatten()

                    for i, ax in enumerate(axes):
                        row = random.randint(0, ny - 1)
                        col = random.randint(0, nx - 1)
                        ts = data_stack[:, row, col].values

                        ax.plot(time_labels, ts, 'o-', markersize=3)
                        ax.set_title(f'åƒå…ƒ ({row}, {col})')
                        ax.set_ylabel('å€¼')
                        ax.tick_params(axis='x', rotation=45)
                        ax.grid(True, alpha=0.3)

                    plt.tight_layout()
                    st.pyplot(fig)
                    plt.close(fig)

            with tab3:
                st.write("æ•°æ®ç»Ÿè®¡:")
                stats_data = {
                    'æœ€å°å€¼': float(data_stack.min()),
                    'æœ€å¤§å€¼': float(data_stack.max()),
                    'å¹³å‡å€¼': float(data_stack.mean()),
                    'æ ‡å‡†å·®': float(data_stack.std())
                }
                for key, value in stats_data.items():
                    st.write(f"- {key}: {value:.4f}")

        # ---------------------------
        # åˆ†ææ§åˆ¶
        # ---------------------------
        st.sidebar.header("ğŸ”§ åˆ†ææ§åˆ¶")

        # åˆ†æé€‰æ‹©
        st.sidebar.subheader("é€‰æ‹©åˆ†ææ–¹æ³•")
        analysis_options = {
            "Theilâ€“Sen è¶‹åŠ¿åˆ†æ": "theilsen",
            "Mannâ€“Kendall æ£€éªŒ": "mk",
            "BFAST çªå˜æ£€æµ‹": "bfast",
            "FFT å‘¨æœŸåˆ†æ": "fft",
            "STL åˆ†è§£": "stl"
        }

        selected_analyses = []
        for name, key in analysis_options.items():
            if st.sidebar.checkbox(name, value=True, key=f"checkbox_{key}"):
                selected_analyses.append(key)

        # æ ¹æ®æ•°æ®é¢‘ç‡è®¾ç½®é»˜è®¤STLå‘¨æœŸ
        default_stl_period = 12  # é»˜è®¤æœˆåº¦æ•°æ®å‘¨æœŸ
        if data_frequency == "å¹´åº¦æ•°æ®":
            default_stl_period = 1
            st.sidebar.info("ğŸ“… å¹´åº¦æ•°æ®æ£€æµ‹ï¼šSTLåˆ†è§£å¯èƒ½ä¸é€‚ç”¨")

        if 'stl' in selected_analyses:
            stl_period = st.sidebar.number_input(
                "STL å‘¨æœŸå‚æ•°",
                value=default_stl_period,
                min_value=1,
                max_value=min(24, len(times) // 2),
                help="å­£èŠ‚å‘¨æœŸé•¿åº¦ï¼Œæœˆåº¦æ•°æ®é€šå¸¸ä¸º12ï¼Œå¹´åº¦æ•°æ®é€šå¸¸ä¸º1"
            )

        # æ‰§è¡ŒæŒ‰é’®
        run_analysis = st.sidebar.button(
            "ğŸš€ æ‰§è¡Œé€‰ä¸­åˆ†æ",
            type="primary",
            use_container_width=True
        )

        if run_analysis and selected_analyses:
            # åˆ›å»ºè¿›åº¦æ˜¾ç¤ºåŒºåŸŸ
            progress_container = st.container()
            with progress_container:
                st.subheader("åˆ†æè¿›åº¦")
                progress_bar = st.progress(0)
                status_text = st.empty()
                percent_text = st.empty()
                time_elapsed_text = st.empty()

            start_time = datetime.datetime.now()

            try:
                total_analyses = len(selected_analyses)
                current_progress = 0


                # æ›´æ–°è¿›åº¦æ˜¾ç¤ºå‡½æ•°
                def update_progress(step_name, progress):
                    progress_bar.progress(progress)
                    percent_text.text(f"è¿›åº¦: {progress * 100:.1f}%")
                    status_text.text(f"ğŸ”„ {step_name}")
                    elapsed = datetime.datetime.now() - start_time
                    time_elapsed_text.text(f"å·²ç”¨æ—¶: {elapsed.seconds // 60}åˆ†{elapsed.seconds % 60}ç§’")


                # Theilâ€“Sen åˆ†æ
                if 'theilsen' in selected_analyses:
                    update_progress("æ­£åœ¨è®¡ç®— Theilâ€“Sen è¶‹åŠ¿...", current_progress / total_analyses)
                    slope_da, intercept_da = theil_sen_trend(data_stack)
                    st.session_state.analysis_results['theilsen'] = {
                        'slope': slope_da,
                        'intercept': intercept_da
                    }
                    current_progress += 1
                    update_progress("Theilâ€“Sen è¶‹åŠ¿åˆ†æå®Œæˆ", current_progress / total_analyses)

                # Mannâ€“Kendall åˆ†æ
                if 'mk' in selected_analyses:
                    update_progress("æ­£åœ¨è®¡ç®— Mannâ€“Kendall æ£€éªŒ...", current_progress / total_analyses)
                    mk_da = mann_kendall_test(data_stack)
                    st.session_state.analysis_results['mk'] = mk_da
                    current_progress += 1
                    update_progress("Mannâ€“Kendall æ£€éªŒå®Œæˆ", current_progress / total_analyses)

                # BFAST åˆ†æ
                if 'bfast' in selected_analyses:
                    update_progress("æ­£åœ¨æ£€æµ‹çªå˜ç‚¹...", current_progress / total_analyses)
                    break_da = bfast_detection(data_stack)
                    st.session_state.analysis_results['bfast'] = break_da
                    current_progress += 1
                    update_progress("BFAST çªå˜æ£€æµ‹å®Œæˆ", current_progress / total_analyses)

                # FFT åˆ†æ
                if 'fft' in selected_analyses:
                    update_progress("æ­£åœ¨è¿›è¡Œ FFT å‘¨æœŸåˆ†æ...", current_progress / total_analyses)
                    amp_da, period_da = fft_analysis(data_stack)
                    st.session_state.analysis_results['fft'] = {
                        'amplitude': amp_da,
                        'period': period_da
                    }
                    current_progress += 1
                    update_progress("FFT å‘¨æœŸåˆ†æå®Œæˆ", current_progress / total_analyses)

                # STL åˆ†è§£
                if 'stl' in selected_analyses:
                    if data_frequency == "å¹´åº¦æ•°æ®":
                        st.warning("âš ï¸ å¹´åº¦æ•°æ®ä¸é€‚åˆSTLåˆ†è§£ï¼Œå­£èŠ‚å‘¨æœŸå¯èƒ½æ— æ„ä¹‰")

                    update_progress("æ­£åœ¨æ‰§è¡Œ STL åˆ†è§£...", current_progress / total_analyses)
                    trend_da, seasonal_da, resid_da = stl_decompose_pixelwise(
                        data_stack,
                        period=stl_period
                    )
                    st.session_state.analysis_results['stl'] = {
                        'trend': trend_da,
                        'seasonal': seasonal_da,
                        'resid': resid_da
                    }
                    current_progress += 1
                    update_progress("STL åˆ†è§£å®Œæˆ", current_progress / total_analyses)

                # å®Œæˆæ‰€æœ‰åˆ†æ
                progress_bar.progress(1.0)
                percent_text.text("è¿›åº¦: 100%")
                status_text.text("âœ… æ‰€æœ‰åˆ†æå®Œæˆ!")
                total_time = datetime.datetime.now() - start_time
                time_elapsed_text.text(f"æ€»ç”¨æ—¶: {total_time.seconds // 60}åˆ†{total_time.seconds % 60}ç§’")
                st.balloons()

                # çŸ­æš‚å»¶è¿Ÿåæ¸…é™¤è¿›åº¦æ˜¾ç¤º
                import time

                time.sleep(2)
                progress_container.empty()

            except Exception as e:
                progress_bar.progress(1.0)
                percent_text.text("è¿›åº¦: 100%")
                status_text.text("âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™")
                st.error(f"é”™è¯¯è¯¦æƒ…: {e}")

        # ---------------------------
        # ç»“æœæ˜¾ç¤ºå’Œä¸‹è½½
        # ---------------------------
        if st.session_state.analysis_results:
            st.header("ğŸ“‹ åˆ†æç»“æœ")

            # Theilâ€“Sen ç»“æœ
            if 'theilsen' in st.session_state.analysis_results:
                with st.expander("ğŸ“ˆ Theilâ€“Sen è¶‹åŠ¿åˆ†æç»“æœ", expanded=True):
                    slope_da = st.session_state.analysis_results['theilsen']['slope']
                    col1, col2 = st.columns(2)
                    with col1:
                        plot_map(slope_da, title="Theilâ€“Sen æ–œç‡")
                    with col2:
                        st.download_button(
                            "â¬‡ï¸ ä¸‹è½½æ–œç‡ç»“æœ (GeoTIFF)",
                            data=dataarray_to_bytes_tif(slope_da),
                            file_name="theil_sen_slope.tif",
                            mime="image/tiff",
                            use_container_width=True
                        )

            # Mannâ€“Kendall ç»“æœ
            if 'mk' in st.session_state.analysis_results:
                with st.expander("ğŸ“Š Mannâ€“Kendall æ£€éªŒç»“æœ", expanded=True):
                    mk_da = st.session_state.analysis_results['mk']
                    col1, col2 = st.columns(2)
                    with col1:
                        plot_map(mk_da, title="Mannâ€“Kendall è¶‹åŠ¿ (1=ä¸Šå‡, -1=ä¸‹é™, 0=ä¸æ˜¾è‘—)")
                    with col2:
                        st.download_button(
                            "â¬‡ï¸ ä¸‹è½½ MK ç»“æœ (GeoTIFF)",
                            data=dataarray_to_bytes_tif(mk_da),
                            file_name="mann_kendall.tif",
                            mime="image/tiff",
                            use_container_width=True
                        )

            # BFAST ç»“æœ
            if 'bfast' in st.session_state.analysis_results:
                with st.expander("ğŸ” BFAST çªå˜æ£€æµ‹ç»“æœ", expanded=True):
                    break_da = st.session_state.analysis_results['bfast']
                    col1, col2 = st.columns(2)
                    with col1:
                        plot_map(break_da, title="çªå˜å¹´ä»½ (NaN=æ— çªå˜)")
                    with col2:
                        st.download_button(
                            "â¬‡ï¸ ä¸‹è½½çªå˜å¹´ä»½ (GeoTIFF)",
                            data=dataarray_to_bytes_tif(break_da),
                            file_name="break_years.tif",
                            mime="image/tiff",
                            use_container_width=True
                        )

            # FFT ç»“æœ
            if 'fft' in st.session_state.analysis_results:
                with st.expander("ğŸ“¡ FFT å‘¨æœŸåˆ†æç»“æœ", expanded=True):
                    amp_da = st.session_state.analysis_results['fft']['amplitude']
                    period_da = st.session_state.analysis_results['fft']['period']
                    col1, col2 = st.columns(2)
                    with col1:
                        plot_map(amp_da, title="FFT æŒ¯å¹…")
                        st.download_button(
                            "â¬‡ï¸ ä¸‹è½½ FFT æŒ¯å¹…",
                            data=dataarray_to_bytes_tif(amp_da),
                            file_name="fft_amplitude.tif",
                            mime="image/tiff",
                            use_container_width=True
                        )
                    with col2:
                        plot_map(period_da, title="FFT ä¸»å‘¨æœŸ")
                        st.download_button(
                            "â¬‡ï¸ ä¸‹è½½ FFT å‘¨æœŸ",
                            data=dataarray_to_bytes_tif(period_da),
                            file_name="fft_period.tif",
                            mime="image/tiff",
                            use_container_width=True
                        )

            # STL ç»“æœ
            if 'stl' in st.session_state.analysis_results:
                with st.expander("ğŸ”„ STL åˆ†è§£ç»“æœ", expanded=True):
                    trend_da = st.session_state.analysis_results['stl']['trend']
                    seasonal_da = st.session_state.analysis_results['stl']['seasonal']
                    resid_da = st.session_state.analysis_results['stl']['resid']

                    col1, col2, col3 = st.columns(3)
                    with col1:
                        plot_map(trend_da, title="STL: å¹³å‡è¶‹åŠ¿åˆ†é‡")
                        st.download_button(
                            "â¬‡ï¸ ä¸‹è½½è¶‹åŠ¿åˆ†é‡",
                            data=dataarray_to_bytes_tif(trend_da),
                            file_name="stl_trend_mean.tif",
                            mime="image/tiff",
                            use_container_width=True
                        )
                    with col2:
                        plot_map(seasonal_da, title="STL: å¹³å‡å­£èŠ‚åˆ†é‡")
                        st.download_button(
                            "â¬‡ï¸ ä¸‹è½½å­£èŠ‚åˆ†é‡",
                            data=dataarray_to_bytes_tif(seasonal_da),
                            file_name="stl_seasonal_mean.tif",
                            mime="image/tiff",
                            use_container_width=True
                        )
                    with col3:
                        plot_map(resid_da, title="STL: æ®‹å·®æ ‡å‡†å·®")
                        st.download_button(
                            "â¬‡ï¸ ä¸‹è½½æ®‹å·®æ ‡å‡†å·®",
                            data=dataarray_to_bytes_tif(resid_da),
                            file_name="stl_residual_std.tif",
                            mime="image/tiff",
                            use_container_width=True
                        )

        # ---------------------------
        # äº¤äº’å¼åƒå…ƒåˆ†æ
        # ---------------------------
        st.sidebar.header("ğŸ” åƒå…ƒçº§åˆ†æ")
        with st.expander("ğŸ“ˆ åƒå…ƒæ—¶åºåˆ†æå·¥å…·", expanded=True):
            st.info("ä½¿ç”¨ä¾§è¾¹æ æ»‘æ†é€‰æ‹©ç‰¹å®šåƒå…ƒæŸ¥çœ‹å…¶æ—¶åºç‰¹å¾")

            # æ ¹æ®æ•°æ®é¢‘ç‡è®¾ç½®é»˜è®¤STLå‘¨æœŸ
            pixel_stl_period = 12
            if data_frequency == "å¹´åº¦æ•°æ®":
                pixel_stl_period = 1

            plot_pixel_timeseries(
                data_stack,
                period=st.sidebar.number_input(
                    "STL å‘¨æœŸå‚æ•°",
                    value=pixel_stl_period,
                    min_value=1,
                    max_value=min(24, len(times) // 2),
                    key="pixel_stl_period"
                )
            )

else:
    st.info("ğŸ‘† è¯·åœ¨ä¾§è¾¹æ ä¸Šä¼  GeoTIFF æ–‡ä»¶å¼€å§‹åˆ†æ")

    # ä½¿ç”¨è¯´æ˜
    with st.expander("ğŸ“– ä½¿ç”¨è¯´æ˜", expanded=True):
        st.markdown("""
        ### ğŸ¯ ç³»ç»ŸåŠŸèƒ½
        - **Theilâ€“Senè¶‹åŠ¿åˆ†æ**: è®¡ç®—ç¨³å¥çš„è¶‹åŠ¿æ–œç‡
        - **Mannâ€“Kendallæ£€éªŒ**: æ£€éªŒè¶‹åŠ¿æ˜¾è‘—æ€§  
        - **BFASTçªå˜æ£€æµ‹**: æ£€æµ‹æ—¶é—´åºåˆ—ä¸­çš„çªå˜ç‚¹
        - **FFTå‘¨æœŸåˆ†æ**: åˆ†æå‘¨æœŸæ€§ç‰¹å¾
        - **STLåˆ†è§£**: åˆ†è§£ä¸ºè¶‹åŠ¿ã€å­£èŠ‚å’Œæ®‹å·®åˆ†é‡

        ### ğŸ“ æ•°æ®è¦æ±‚
        - **æ–‡ä»¶æ ¼å¼**: GeoTIFF (.tif, .tiff)
        - **æ—¶é—´ä¿¡æ¯**: æ–‡ä»¶åå¿…é¡»åŒ…å«æ—¶é—´ä¿¡æ¯
        - **å¹´åº¦æ•°æ®å‘½å**: `NDVI_2000.tif`, `NDVI_2001.tif`
        - **æœˆåº¦æ•°æ®å‘½å**: `NDVI_200001.tif`, `NDVI_200002.tif`
        - **ç©ºé—´èŒƒå›´**: æ‰€æœ‰æ–‡ä»¶å¿…é¡»å…·æœ‰ç›¸åŒçš„ç©ºé—´èŒƒå›´å’Œåˆ†è¾¨ç‡
        - **å»ºè®®æ—¶é—´åºåˆ—é•¿åº¦**: â‰¥3æœŸä»¥è·å¾—æœ‰æ„ä¹‰çš„ç»“æœ

        ### âš¡ ä½¿ç”¨æµç¨‹
        1. åœ¨å·¦ä¾§ä¸Šä¼ å¤šä¸ªGeoTIFFæ–‡ä»¶
        2. ç³»ç»Ÿè‡ªåŠ¨æ£€æµ‹æ•°æ®é¢‘ç‡ï¼ˆå¹´åº¦/æœˆåº¦ï¼‰
        3. é€‰æ‹©è¦è¿è¡Œçš„åˆ†ææ–¹æ³•
        4. ç‚¹å‡»"æ‰§è¡Œé€‰ä¸­åˆ†æ"
        5. æŸ¥çœ‹ç»“æœå¹¶ä¸‹è½½

        ### ğŸ’¡ åˆ†æå»ºè®®
        - **å¹´åº¦æ•°æ®**: é€‚åˆè¶‹åŠ¿åˆ†æå’Œçªå˜æ£€æµ‹
        - **æœˆåº¦æ•°æ®**: é€‚åˆæ‰€æœ‰åˆ†ææ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯STLå’ŒFFTå‘¨æœŸåˆ†æ
        """)

# é¡µè„š
st.markdown("---")
st.markdown("ğŸ›°ï¸ æ—¶åºé¥æ„Ÿåˆ†æç³»ç»Ÿ | åŸºäº Python + Streamlit æ„å»º")