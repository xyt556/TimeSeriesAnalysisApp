# app.py
import streamlit as st
import tempfile
from pathlib import Path
import re
import xarray as xr
import rioxarray as rxr
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import warnings
import datetime

warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'STHeiti']
matplotlib.rcParams['axes.unicode_minus'] = False

from utils.analysis_tools import (
    theil_sen_trend,
    mann_kendall_test,
    bfast_detection,
    fft_analysis,
    stl_decompose_pixelwise
)
from utils.visualization import (
    plot_map,
    plot_pixel_timeseries,
    dataarray_to_bytes_tif,
    fig_to_bytes_png
)

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ—¶åºé¥æ„Ÿåˆ†æç³»ç»Ÿ_V2.0 @3S&ML",
    layout="wide",
    page_icon="ğŸ›°ï¸"
)

st.title("ğŸ›°ï¸ æ—¶åºé¥æ„Ÿåˆ†æç³»ç»Ÿ")
st.markdown("""
**åŠŸèƒ½æ¨¡å—ï¼š** Theilâ€“Senè¶‹åŠ¿åˆ†æ | Mannâ€“Kendallæ£€éªŒ | BFASTçªå˜æ£€æµ‹ | FFTå‘¨æœŸåˆ†æ | STLåˆ†è§£
""")


# ---------------------------
# æ–‡ä»¶ä¸Šä¼ ä¸é¢„å¤„ç†
# ---------------------------
@st.cache_data(show_spinner=False)
def extract_time(filename):
    """
    ä»æ–‡ä»¶åä¸­æå–æ—¶é—´ä¿¡æ¯ï¼Œæ”¯æŒå¤šç§æ ¼å¼
    è¿”å› datetime å¯¹è±¡
    """
    # å°è¯•åŒ¹é… YYYY_DDD æ ¼å¼ (2020_001, 2020_365)
    m = re.search(r'(19\d{2}|20\d{2})_(\d{3})', filename)
    if m:
        year = int(m.group(1))
        day_of_year = int(m.group(2))
        # å°†ä¸€å¹´ä¸­çš„ç¬¬å‡ å¤©è½¬æ¢ä¸ºæœˆä»½å’Œæ—¥æœŸ
        try:
            date = datetime.datetime(year, 1, 1) + datetime.timedelta(days=day_of_year - 1)
            return date
        except:
            return datetime.datetime(year, 1, 1)

    # å°è¯•åŒ¹é… YYYY_MM æ ¼å¼ (2020_01, 2020_12)
    m = re.search(r'(19\d{2}|20\d{2})_(\d{1,2})', filename)
    if m:
        year = int(m.group(1))
        month = int(m.group(2))
        return datetime.datetime(year, month, 1)

    # å°è¯•åŒ¹é… YYYYMM æ ¼å¼ (202001, 202012)
    m = re.search(r'(19\d{2}|20\d{2})(\d{2})', filename)
    if m:
        year = int(m.group(1))
        month = int(m.group(2))
        return datetime.datetime(year, month, 1)

    # å°è¯•åŒ¹é… YYYY æ ¼å¼ (2000, 2001)
    m = re.search(r'(19\d{2}|20\d{2})', filename)
    if m:
        year = int(m.group(0))
        return datetime.datetime(year, 1, 1)  # å¹´åº¦æ•°æ®é»˜è®¤è®¾ä¸º1æœˆ1æ—¥

    # å°è¯•åŒ¹é…è‹±æ–‡æœˆä»½
    month_map = {
        'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6,
        'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12
    }

    for month_name, month_num in month_map.items():
        if month_name in filename:
            m = re.search(r'(19\d{2}|20\d{2})', filename)
            if m:
                year = int(m.group(0))
                return datetime.datetime(year, month_num, 1)

    return None


@st.cache_data(show_spinner=False)
def load_and_stack_files(_uploaded_files):
    """åŠ è½½å¹¶å †å æ–‡ä»¶ - ç¡®ä¿ä¿æŒåæ ‡ç³»"""
    tmpdir = Path(tempfile.mkdtemp())
    paths = []

    for f in _uploaded_files:
        p = tmpdir / f.name
        p.write_bytes(f.getbuffer())
        paths.append(p)

    # æå–æ—¶é—´ä¿¡æ¯
    times = [extract_time(f.name) for f in _uploaded_files]

    # æ£€æŸ¥æ—¶é—´æå–
    invalid_files = [(f.name, t) for f, t in zip(_uploaded_files, times) if t is None]
    if invalid_files:
        st.error("ä»¥ä¸‹æ–‡ä»¶ä¸­æœªæ£€æµ‹åˆ°æœ‰æ•ˆæ—¶é—´ä¿¡æ¯:")
        for fname, time_val in invalid_files:
            st.error(f"  - {fname}")
        st.info("ğŸ’¡ æ”¯æŒçš„æ–‡ä»¶åæ ¼å¼:")
        st.info("   - å¹´åº¦æ•°æ®: NDVI_2000.tif, NDVI_2001_å¾å·.tif")
        st.info("   - æœˆåº¦æ•°æ®: NDVI_200001.tif, NDVI_2000_01.tif, NDVI_2000_01_å¾å·.tif")
        st.info("   - æ—¥åº¦æ•°æ®: NDVI_2000_001.tif, NDVI_2000_365_å¾å·.tif")
        return None

    # æŒ‰æ—¶é—´æ’åºå¹¶æ£€æŸ¥é‡å¤
    sorted_indices = sorted(range(len(times)), key=lambda i: times[i])
    paths = [paths[i] for i in sorted_indices]
    times = [times[i] for i in sorted_indices]
    _uploaded_files = [_uploaded_files[i] for i in sorted_indices]

    # æ£€æŸ¥æ—¶é—´é‡å¤å¹¶æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    time_count = {}
    for f, t in zip(_uploaded_files, times):
        if t not in time_count:
            time_count[t] = []
        time_count[t].append(f.name)

    duplicate_times = [t for t, files in time_count.items() if len(files) > 1]

    if duplicate_times:
        st.warning("âš ï¸ æ£€æµ‹åˆ°é‡å¤çš„æ—¶é—´ç‚¹:")
        for t in duplicate_times:
            st.error(f"æ—¶é—´ {t.strftime('%Y-%m-%d')} å¯¹åº”çš„æ–‡ä»¶:")
            for fname in time_count[t]:
                st.error(f"  - {fname}")
        st.info("æ—¶åºåˆ†æè¦æ±‚æ¯ä¸ªæ—¶é—´ç‚¹åªæœ‰ä¸€ä¸ªè§‚æµ‹å€¼ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶å‘½åã€‚")

        # è¯¢é—®ç”¨æˆ·æ˜¯å¦ç»§ç»­
        continue_anyway = st.checkbox("å¿½ç•¥é‡å¤æ—¶é—´ç‚¹ï¼Œç»§ç»­åˆ†æ", value=False)
        if not continue_anyway:
            return None

    # è¯»å–æ•°æ®å¹¶ä¿æŒåæ ‡ç³»
    data_list = []
    time_coords = []
    reference_da = None

    for p, t in zip(paths, times):
        try:
            da = rxr.open_rasterio(str(p), chunks={'x': 512, 'y': 512}).squeeze()
            if "band" in da.dims:
                da = da.isel(band=0).drop_vars('band')

            # ç¡®ä¿æ•°æ®æ˜¯2Dçš„ (y, x)
            if da.ndim != 2:
                st.error(f"æ–‡ä»¶ {p.name} çš„ç»´åº¦ä¸æ­£ç¡®ï¼ŒæœŸæœ›2Dæ•°æ® (y, x)ï¼Œå®é™…ç»´åº¦: {da.dims}")
                continue

            # ä¿å­˜ç¬¬ä¸€ä¸ªæ•°æ®ä½œä¸ºå‚è€ƒ
            if reference_da is None:
                reference_da = da

            data_list.append(da)
            time_coords.append(t)

        except Exception as e:
            st.error(f"è¯»å–æ–‡ä»¶ {p.name} æ—¶å‡ºé”™: {e}")
            continue

    if not data_list:
        st.error("æ²¡æœ‰æˆåŠŸè¯»å–ä»»ä½•æ–‡ä»¶")
        return None

    # å †å æ•°æ®
    try:
        stack = xr.concat(data_list, dim="time")
        stack = stack.assign_coords(time=time_coords)
        stack = stack.transpose('time', 'y', 'x')

        # å¦‚æœå‚è€ƒæ•°æ®æœ‰åæ ‡ç³»ä¿¡æ¯ï¼Œå°è¯•åº”ç”¨åˆ°å †å æ•°æ®
        if reference_da is not None:
            if hasattr(reference_da, 'rio') and reference_da.rio.crs is not None:
                try:
                    stack.rio.set_crs(reference_da.rio.crs)
                except Exception as e:
                    st.warning(f"æ— æ³•è®¾ç½®åæ ‡ç³»: {e}")

        # éªŒè¯æ•°æ®å½¢çŠ¶å’Œæ˜¾ç¤ºä¿¡æ¯
        st.info(f"æ•°æ®æ ˆå½¢çŠ¶: {stack.shape} (æ—¶é—´, Y, X)")

        # æ˜¾ç¤ºåæ ‡ç³»ä¿¡æ¯
        if hasattr(stack, 'rio') and hasattr(stack.rio, 'crs') and stack.rio.crs is not None:
            st.success(f"âœ… æ£€æµ‹åˆ°åæ ‡ç³»: {stack.rio.crs}")
        else:
            st.warning("âš ï¸ æœªæ£€æµ‹åˆ°åæ ‡ç³»ä¿¡æ¯")

        return stack

    except Exception as e:
        st.error(f"æ•°æ®å †å å¤±è´¥: {e}")
        return None


# åˆå§‹åŒ–session state
if 'analysis_results' not in st.session_state:
    st.session_state.analysis_results = {}
if 'data_stack' not in st.session_state:
    st.session_state.data_stack = None

# æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
st.sidebar.header("ğŸ“ æ•°æ®ä¸Šä¼ ")
uploaded_files = st.sidebar.file_uploader(
    "ä¸Šä¼ å¤šæœŸ GeoTIFF æ–‡ä»¶",
    type=["tif", "tiff"],
    accept_multiple_files=True,
    help="æ–‡ä»¶ååº”åŒ…å«å¹´ä»½ï¼Œå¦‚: NDVI_2000.tif (å¹´åº¦) æˆ– NDVI_200001.tif (æœˆåº¦)"
)

if uploaded_files:
    # æŒ‰æ–‡ä»¶åæ’åºä»¥ç¡®ä¿ä¸€è‡´æ€§
    uploaded_files = sorted(uploaded_files, key=lambda f: f.name)

    # åŠ è½½æ•°æ®
    with st.spinner("ğŸ”„ æ­£åœ¨åŠ è½½å’Œå¤„ç†æ …æ ¼æ•°æ®..."):
        data_stack = load_and_stack_files(uploaded_files)

    if data_stack is not None:
        st.session_state.data_stack = data_stack

        # æ£€æµ‹æ•°æ®ç±»å‹å¹¶æ˜¾ç¤ºä¿¡æ¯
        times = data_stack.time.values
        time_labels = []
        for t in times:
            if isinstance(t, np.datetime64):
                time_labels.append(np.datetime_as_string(t, unit='D'))
            else:
                time_labels.append(str(t))

        # åˆ¤æ–­æ•°æ®é¢‘ç‡
        data_frequency = "å¹´åº¦æ•°æ®"
        if len(times) > 1:
            if isinstance(times[0], np.datetime64):
                time_diff = times[1] - times[0]
                days_diff = time_diff / np.timedelta64(1, 'D')
                if 28 <= days_diff <= 31:
                    data_frequency = "æœˆåº¦æ•°æ®"
                elif 360 <= days_diff <= 370:
                    data_frequency = "å¹´åº¦æ•°æ®"

        # æ˜¾ç¤ºæ•°æ®ä¿¡æ¯
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("æ•°æ®é¢‘ç‡", data_frequency)
        with col2:
            st.metric("æ—¶é—´åºåˆ—é•¿åº¦", f"{data_stack.sizes['time']} æœŸ")
        with col3:
            st.metric("ç©ºé—´åˆ†è¾¨ç‡", f"{data_stack.sizes['y']} Ã— {data_stack.sizes['x']}")
        with col4:
            if len(time_labels) > 0:
                st.metric("æ—¶é—´èŒƒå›´", f"{time_labels[0]} è‡³ {time_labels[-1]}")

        # æ•°æ®é¢„è§ˆ
        with st.expander("ğŸ“Š æ•°æ®é¢„è§ˆ", expanded=True):
            tab1, tab2, tab3, tab4 = st.tabs(["ç©ºé—´åˆ†å¸ƒ", "æ—¶é—´åºåˆ—æŠ½æ ·", "ç»Ÿè®¡ä¿¡æ¯", "åæ ‡ç³»ç»Ÿ"])

            with tab1:
                st.subheader("ç¬¬ä¸€æœŸæ …æ ¼é¢„è§ˆ")
                plot_map(data_stack.isel(time=0),
                         title=f"æ—¶é—´: {time_labels[0]}")

            with tab2:
                st.subheader("éšæœºåƒå…ƒæ—¶é—´åºåˆ—æŠ½æ ·")
                # éšæœºé€‰æ‹©å‡ ä¸ªåƒå…ƒæ˜¾ç¤ºæ—¶é—´åºåˆ—
                ny, nx = data_stack.sizes['y'], data_stack.sizes['x']
                if ny > 0 and nx > 0:
                    # éšæœºé€‰æ‹©å‡ ä¸ªä½ç½®
                    import random

                    fig, axes = plt.subplots(2, 2, figsize=(12, 8))
                    axes = axes.flatten()

                    for i, ax in enumerate(axes):
                        row = random.randint(0, ny - 1)
                        col = random.randint(0, nx - 1)
                        ts = data_stack[:, row, col].values

                        ax.plot(time_labels, ts, 'o-', markersize=3)
                        ax.set_title(f'åƒå…ƒ ({row}, {col})')
                        ax.set_ylabel('å€¼')
                        ax.tick_params(axis='x', rotation=45)
                        ax.grid(True, alpha=0.3)

                    plt.tight_layout()
                    st.pyplot(fig)
                    plt.close(fig)

            with tab3:
                st.write("æ•°æ®ç»Ÿè®¡:")
                stats_data = {
                    'æœ€å°å€¼': float(data_stack.min()),
                    'æœ€å¤§å€¼': float(data_stack.max()),
                    'å¹³å‡å€¼': float(data_stack.mean()),
                    'æ ‡å‡†å·®': float(data_stack.std())
                }
                for key, value in stats_data.items():
                    st.write(f"- {key}: {value:.4f}")

            with tab4:
                st.subheader("åæ ‡ç³»ç»Ÿä¿¡æ¯")
                try:
                    # æ£€æŸ¥åæ ‡ç³»
                    if hasattr(data_stack, 'rio') and hasattr(data_stack.rio, 'crs'):
                        crs = data_stack.rio.crs
                        if crs is not None:
                            st.success(f"âœ… åæ ‡ç³»: {crs}")

                            # æ˜¾ç¤ºWKTæ ¼å¼ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                            try:
                                st.text_area("åæ ‡ç³»è¯¦æƒ… (WKT):", str(crs.to_wkt()), height=150)
                            except:
                                st.text_area("åæ ‡ç³»è¯¦æƒ…:", str(crs), height=100)
                        else:
                            st.warning("âš ï¸ æœªæ£€æµ‹åˆ°åæ ‡ç³»ä¿¡æ¯")
                    else:
                        st.warning("âš ï¸ æœªæ£€æµ‹åˆ°åæ ‡ç³»ä¿¡æ¯")

                    # æ˜¾ç¤ºç©ºé—´èŒƒå›´
                    try:
                        if hasattr(data_stack, 'x') and hasattr(data_stack, 'y'):
                            x_coords = data_stack.x.values
                            y_coords = data_stack.y.values
                            if len(x_coords) > 0 and len(y_coords) > 0:
                                st.write(f"XèŒƒå›´: {x_coords[0]:.2f} åˆ° {x_coords[-1]:.2f}")
                                st.write(f"YèŒƒå›´: {y_coords[0]:.2f} åˆ° {y_coords[-1]:.2f}")
                                if len(x_coords) > 1 and len(y_coords) > 1:
                                    x_res = x_coords[1] - x_coords[0]
                                    y_res = y_coords[1] - y_coords[0]
                                    st.write(f"ç©ºé—´åˆ†è¾¨ç‡: {x_res:.6f} Ã— {abs(y_res):.6f}")
                    except Exception as e:
                        st.write(f"æ— æ³•è·å–ç©ºé—´èŒƒå›´: {e}")

                    # æ˜¾ç¤ºå˜æ¢ä¿¡æ¯
                    try:
                        if hasattr(data_stack, 'rio') and hasattr(data_stack.rio, 'transform'):
                            transform = data_stack.rio.transform()
                            if transform:
                                st.write("ä»¿å°„å˜æ¢å‚æ•°:")
                                st.write(f"- å·¦ä¸ŠX: {transform.c}")
                                st.write(f"- å·¦ä¸ŠY: {transform.f}")
                                st.write(f"- Xåˆ†è¾¨ç‡: {transform.a}")
                                st.write(f"- Yåˆ†è¾¨ç‡: {transform.e}")
                    except Exception as e:
                        st.write(f"æ— æ³•è·å–å˜æ¢ä¿¡æ¯: {e}")

                except Exception as e:
                    st.error(f"è·å–åæ ‡ç³»ä¿¡æ¯å¤±è´¥: {e}")

        # ---------------------------
        # åˆ†ææ§åˆ¶
        # ---------------------------
        st.sidebar.header("ğŸ”§ åˆ†ææ§åˆ¶")

        # åˆ†æé€‰æ‹©
        st.sidebar.subheader("é€‰æ‹©åˆ†ææ–¹æ³•")
        analysis_options = {
            "Theilâ€“Sen è¶‹åŠ¿åˆ†æ": "theilsen",
            "Mannâ€“Kendall æ£€éªŒ": "mk",
            "BFAST çªå˜æ£€æµ‹": "bfast",
            "FFT å‘¨æœŸåˆ†æ": "fft",
            "STL åˆ†è§£": "stl"
        }

        selected_analyses = []
        for name, key in analysis_options.items():
            if st.sidebar.checkbox(name, value=True, key=f"checkbox_{key}"):
                selected_analyses.append(key)

        # æ ¹æ®æ•°æ®é¢‘ç‡è®¾ç½®é»˜è®¤STLå‘¨æœŸ
        default_stl_period = 12  # é»˜è®¤æœˆåº¦æ•°æ®å‘¨æœŸ
        if data_frequency == "å¹´åº¦æ•°æ®":
            default_stl_period = 1
            st.sidebar.info("ğŸ“… å¹´åº¦æ•°æ®æ£€æµ‹ï¼šSTLåˆ†è§£å¯èƒ½ä¸é€‚ç”¨")

        if 'stl' in selected_analyses:
            stl_period = st.sidebar.number_input(
                "STL å‘¨æœŸå‚æ•°",
                value=default_stl_period,
                min_value=1,
                max_value=min(24, len(times) // 2),
                help="å­£èŠ‚å‘¨æœŸé•¿åº¦ï¼Œæœˆåº¦æ•°æ®é€šå¸¸ä¸º12ï¼Œå¹´åº¦æ•°æ®é€šå¸¸ä¸º1"
            )

        # æ‰§è¡ŒæŒ‰é’®
        run_analysis = st.sidebar.button(
            "ğŸš€ æ‰§è¡Œé€‰ä¸­åˆ†æ",
            type="primary",
            use_container_width=True
        )

        if run_analysis and selected_analyses:
            # åˆ›å»ºè¿›åº¦æ˜¾ç¤ºåŒºåŸŸ
            progress_container = st.container()
            with progress_container:
                st.subheader("åˆ†æè¿›åº¦")
                progress_bar = st.progress(0)
                status_text = st.empty()
                percent_text = st.empty()
                time_elapsed_text = st.empty()

            start_time = datetime.datetime.now()

            try:
                total_analyses = len(selected_analyses)
                current_progress = 0


                # æ›´æ–°è¿›åº¦æ˜¾ç¤ºå‡½æ•°
                def update_progress(step_name, progress):
                    progress_bar.progress(progress)
                    percent_text.text(f"è¿›åº¦: {progress * 100:.1f}%")
                    status_text.text(f"ğŸ”„ {step_name}")
                    elapsed = datetime.datetime.now() - start_time
                    time_elapsed_text.text(f"å·²ç”¨æ—¶: {elapsed.seconds // 60}åˆ†{elapsed.seconds % 60}ç§’")


                # Theilâ€“Sen åˆ†æ
                if 'theilsen' in selected_analyses:
                    update_progress("æ­£åœ¨è®¡ç®— Theilâ€“Sen è¶‹åŠ¿...", current_progress / total_analyses)
                    try:
                        slope_da, intercept_da = theil_sen_trend(data_stack)
                        st.session_state.analysis_results['theilsen'] = {
                            'slope': slope_da,
                            'intercept': intercept_da
                        }
                    except Exception as e:
                        st.error(f"Theilâ€“Sen åˆ†æå¤±è´¥: {e}")
                    current_progress += 1
                    update_progress("Theilâ€“Sen è¶‹åŠ¿åˆ†æå®Œæˆ", current_progress / total_analyses)

                # Mannâ€“Kendall åˆ†æ
                if 'mk' in selected_analyses:
                    update_progress("æ­£åœ¨è®¡ç®— Mannâ€“Kendall æ£€éªŒ...", current_progress / total_analyses)
                    try:
                        mk_da = mann_kendall_test(data_stack)
                        st.session_state.analysis_results['mk'] = mk_da
                    except Exception as e:
                        st.error(f"Mannâ€“Kendall æ£€éªŒå¤±è´¥: {e}")
                    current_progress += 1
                    update_progress("Mannâ€“Kendall æ£€éªŒå®Œæˆ", current_progress / total_analyses)

                # BFAST åˆ†æ
                if 'bfast' in selected_analyses:
                    update_progress("æ­£åœ¨æ£€æµ‹çªå˜ç‚¹...", current_progress / total_analyses)
                    try:
                        break_da = bfast_detection(data_stack)

                        # ä¿®å¤æ—¶é—´è½¬æ¢é—®é¢˜
                        from utils.analysis_tools import fix_bfast_results

                        break_da_fixed = fix_bfast_results(break_da)

                        st.session_state.analysis_results['bfast'] = break_da_fixed
                    except Exception as e:
                        st.error(f"BFAST çªå˜æ£€æµ‹å¤±è´¥: {e}")
                    current_progress += 1
                    update_progress("BFAST çªå˜æ£€æµ‹å®Œæˆ", current_progress / total_analyses)

                # FFT åˆ†æ
                if 'fft' in selected_analyses:
                    update_progress("æ­£åœ¨è¿›è¡Œ FFT å‘¨æœŸåˆ†æ...", current_progress / total_analyses)
                    try:
                        amp_da, period_da = fft_analysis(data_stack)
                        st.session_state.analysis_results['fft'] = {
                            'amplitude': amp_da,
                            'period': period_da
                        }
                    except Exception as e:
                        st.error(f"FFT å‘¨æœŸåˆ†æå¤±è´¥: {e}")
                    current_progress += 1
                    update_progress("FFT å‘¨æœŸåˆ†æå®Œæˆ", current_progress / total_analyses)

                # STL åˆ†è§£
                if 'stl' in selected_analyses:
                    if data_frequency == "å¹´åº¦æ•°æ®":
                        st.warning("âš ï¸ å¹´åº¦æ•°æ®ä¸é€‚åˆSTLåˆ†è§£ï¼Œå­£èŠ‚å‘¨æœŸå¯èƒ½æ— æ„ä¹‰")

                    update_progress("æ­£åœ¨æ‰§è¡Œ STL åˆ†è§£...", current_progress / total_analyses)
                    try:
                        trend_da, seasonal_da, resid_da = stl_decompose_pixelwise(
                            data_stack,
                            period=stl_period
                        )
                        st.session_state.analysis_results['stl'] = {
                            'trend': trend_da,
                            'seasonal': seasonal_da,
                            'resid': resid_da
                        }
                    except Exception as e:
                        st.error(f"STL åˆ†è§£å¤±è´¥: {e}")
                    current_progress += 1
                    update_progress("STL åˆ†è§£å®Œæˆ", current_progress / total_analyses)

                # å®Œæˆæ‰€æœ‰åˆ†æ
                progress_bar.progress(1.0)
                percent_text.text("è¿›åº¦: 100%")
                status_text.text("âœ… æ‰€æœ‰åˆ†æå®Œæˆ!")
                total_time = datetime.datetime.now() - start_time
                time_elapsed_text.text(f"æ€»ç”¨æ—¶: {total_time.seconds // 60}åˆ†{total_time.seconds % 60}ç§’")
                st.balloons()

                # çŸ­æš‚å»¶è¿Ÿåæ¸…é™¤è¿›åº¦æ˜¾ç¤º
                import time

                time.sleep(2)
                progress_container.empty()

            except Exception as e:
                progress_bar.progress(1.0)
                percent_text.text("è¿›åº¦: 100%")
                status_text.text("âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™")
                st.error(f"é”™è¯¯è¯¦æƒ…: {e}")

        # ---------------------------
        # ç»“æœæ˜¾ç¤ºå’Œä¸‹è½½
        # ---------------------------
        if st.session_state.analysis_results:
            st.header("ğŸ“‹ åˆ†æç»“æœ")

            # Theilâ€“Sen ç»“æœ
            if 'theilsen' in st.session_state.analysis_results:
                with st.expander("ğŸ“ˆ Theilâ€“Sen è¶‹åŠ¿åˆ†æç»“æœ", expanded=True):
                    slope_da = st.session_state.analysis_results['theilsen']['slope']
                    col1, col2 = st.columns(2)
                    with col1:
                        plot_map(slope_da, title="Theilâ€“Sen æ–œç‡")
                    with col2:
                        st.download_button(
                            "â¬‡ï¸ ä¸‹è½½æ–œç‡ç»“æœ (GeoTIFF)",
                            data=dataarray_to_bytes_tif(slope_da),
                            file_name="theil_sen_slope.tif",
                            mime="image/tiff",
                            use_container_width=True,
                            help="ä¸‹è½½çš„TIFFæ–‡ä»¶å°†ä¿æŒåŸå§‹åæ ‡ç³»å’Œç©ºé—´å‚è€ƒä¿¡æ¯"
                        )

            # Mannâ€“Kendall ç»“æœ
            if 'mk' in st.session_state.analysis_results:
                with st.expander("ğŸ“Š Mannâ€“Kendall æ£€éªŒç»“æœ", expanded=True):
                    mk_da = st.session_state.analysis_results['mk']
                    col1, col2 = st.columns(2)
                    with col1:
                        # ä½¿ç”¨ä¸“é—¨çš„MKç»˜å›¾å‚æ•°
                        plot_map(mk_da, title="Mannâ€“Kendall è¶‹åŠ¿ (1=ä¸Šå‡, -1=ä¸‹é™, 0=ä¸æ˜¾è‘—)",
                                 vmin=-1, vmax=1)

                        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                        mk_values = mk_da.values
                        valid_mask = ~np.isnan(mk_values)
                        if np.any(valid_mask):
                            valid_values = mk_values[valid_mask]
                            st.write("è¶‹åŠ¿ç»Ÿè®¡:")
                            st.write(f"- æ˜¾è‘—ä¸Šå‡: {np.sum(valid_values == 1)} åƒå…ƒ")
                            st.write(f"- æ˜¾è‘—ä¸‹é™: {np.sum(valid_values == -1)} åƒå…ƒ")
                            st.write(f"- æ— æ˜¾è‘—è¶‹åŠ¿: {np.sum(valid_values == 0)} åƒå…ƒ")

                    with col2:
                        st.download_button(
                            "â¬‡ï¸ ä¸‹è½½ MK ç»“æœ (GeoTIFF)",
                            data=dataarray_to_bytes_tif(mk_da),
                            file_name="mann_kendall.tif",
                            mime="image/tiff",
                            use_container_width=True,
                            help="ä¸‹è½½çš„TIFFæ–‡ä»¶å°†ä¿æŒåŸå§‹åæ ‡ç³»å’Œç©ºé—´å‚è€ƒä¿¡æ¯"
                        )

            # BFAST ç»“æœ
            if 'bfast' in st.session_state.analysis_results:
                with st.expander("ğŸ” BFAST çªå˜æ£€æµ‹ç»“æœ", expanded=True):
                    break_da = st.session_state.analysis_results['bfast']

                    # æ·»åŠ ç»“æœè§£é‡Š
                    st.info("""
                    **ç»“æœè§£è¯»æŒ‡å—ï¼š**
                    - **æ•°å€¼**: æ£€æµ‹åˆ°çš„çªå˜å‘ç”Ÿå¹´ä»½ï¼ˆå¦‚ 2020, 2021 ç­‰ï¼‰
                    - **NaN**: æ— æ˜¾è‘—çªå˜
                    - **çªå˜å«ä¹‰**: æ—¶é—´åºåˆ—ä¸­å‘ç”Ÿæ˜¾è‘—å˜åŒ–çš„æ—¶åˆ»ï¼Œå¯èƒ½å¯¹åº”è‡ªç„¶ç¾å®³ã€äººç±»æ´»åŠ¨ã€æ”¿ç­–å˜åŒ–ç­‰äº‹ä»¶
                    """)

                    col1, col2 = st.columns(2)
                    with col1:
                        # å¯¹BFASTç»“æœè¿›è¡Œç‰¹æ®Šå¤„ç†ï¼Œç¡®ä¿æ˜¾ç¤ºæ­£ç¡®çš„å¹´ä»½
                        break_values = break_da.values

                        # è¿‡æ»¤æ‰å¼‚å¸¸å¤§çš„å€¼ï¼ˆå¯èƒ½æ˜¯æœªè½¬æ¢çš„æ—¶é—´æˆ³ï¼‰
                        if np.nanmax(break_values) > 3000:  # å¦‚æœæœ€å¤§å€¼è¶…è¿‡3000ï¼Œè¯´æ˜å¯èƒ½æ˜¯æ—¶é—´æˆ³
                            st.warning("âš ï¸ æ£€æµ‹åˆ°å¼‚å¸¸æ—¶é—´å€¼ï¼Œæ­£åœ¨è¿›è¡Œè½¬æ¢...")
                            # è½¬æ¢æ—¶é—´æˆ³åˆ°å¹´ä»½
                            break_values_converted = np.full_like(break_values, np.nan)
                            for i in range(break_values.shape[0]):
                                for j in range(break_values.shape[1]):
                                    val = break_values[i, j]
                                    if not np.isnan(val):
                                        if val > 1000000000000000000:  # å¯èƒ½æ˜¯çº³ç§’æ—¶é—´æˆ³
                                            # è½¬æ¢ä¸ºå¹´ä»½
                                            try:
                                                dt = pd.to_datetime(val)
                                                break_values_converted[i, j] = dt.year
                                            except:
                                                break_values_converted[i, j] = np.nan
                                        elif val > 3000:  # å¼‚å¸¸å¤§çš„å¹´ä»½å€¼
                                            break_values_converted[i, j] = np.nan
                                        else:
                                            break_values_converted[i, j] = val

                            # åˆ›å»ºæ–°çš„DataArray
                            break_da_corrected = xr.DataArray(
                                break_values_converted,
                                dims=break_da.dims,
                                coords=break_da.coords
                            )

                            # æ›´æ–°session stateä¸­çš„ç»“æœ
                            st.session_state.analysis_results['bfast'] = break_da_corrected
                            break_da = break_da_corrected

                        plot_map(break_da, title="çªå˜å¹´ä»½ (NaN=æ— çªå˜)")

                        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                        break_values = break_da.values
                        valid_mask = ~np.isnan(break_values)
                        if np.any(valid_mask):
                            valid_years = break_values[valid_mask]

                            # è¿‡æ»¤å¼‚å¸¸å¹´ä»½ï¼ˆåªä¿ç•™åˆç†çš„å¹´ä»½èŒƒå›´ï¼‰
                            current_year = datetime.datetime.now().year
                            valid_years_filtered = valid_years[
                                (valid_years >= 1900) & (valid_years <= current_year + 1)
                                ]

                            st.write("çªå˜ç»Ÿè®¡:")
                            st.write(f"- æ£€æµ‹åˆ°çªå˜çš„åƒå…ƒ: {len(valid_years_filtered)} ä¸ª")

                            # æ˜¾ç¤ºçªå˜å¹´ä»½åˆ†å¸ƒ
                            if len(valid_years_filtered) > 0:
                                unique_years, counts = np.unique(valid_years_filtered.astype(int), return_counts=True)
                                st.write("çªå˜å¹´ä»½åˆ†å¸ƒ:")
                                for year, count in zip(unique_years, counts):
                                    st.write(f"  - {year}å¹´: {count} åƒå…ƒ")

                                # ç»˜åˆ¶å¹´ä»½åˆ†å¸ƒå›¾
                                fig, ax = plt.subplots(figsize=(10, 4))
                                ax.bar(unique_years, counts, color='skyblue', alpha=0.7)
                                ax.set_xlabel('å¹´ä»½')
                                ax.set_ylabel('åƒå…ƒæ•°é‡')
                                ax.set_title('çªå˜å¹´ä»½åˆ†å¸ƒ')
                                ax.grid(True, alpha=0.3)
                                plt.xticks(rotation=45)
                                plt.tight_layout()
                                st.pyplot(fig)
                                plt.close(fig)

                    with col2:
                        st.download_button(
                            "â¬‡ï¸ ä¸‹è½½çªå˜å¹´ä»½ (GeoTIFF)",
                            data=dataarray_to_bytes_tif(break_da),
                            file_name="break_years.tif",
                            mime="image/tiff",
                            use_container_width=True,
                            help="ä¸‹è½½çš„TIFFæ–‡ä»¶ä¸­ï¼Œåƒå…ƒå€¼ä»£è¡¨çªå˜å‘ç”Ÿçš„å¹´ä»½ï¼ŒNaNè¡¨ç¤ºæ— çªå˜"
                        )

                        # æ·»åŠ æ•°æ®è¯´æ˜
                        st.markdown("""
                        **æ•°æ®è¯´æ˜ï¼š**
                        - åƒå…ƒå€¼ï¼šçªå˜å‘ç”Ÿçš„å…·ä½“å¹´ä»½
                        - æ•°æ®èŒƒå›´ï¼š1900-å½“å‰å¹´ä»½
                        - å¼‚å¸¸å€¼å·²è‡ªåŠ¨è¿‡æ»¤
                        """)

            # FFT ç»“æœ
            if 'fft' in st.session_state.analysis_results:
                with st.expander("ğŸ“¡ FFT å‘¨æœŸåˆ†æç»“æœ", expanded=True):
                    amp_da = st.session_state.analysis_results['fft']['amplitude']
                    period_da = st.session_state.analysis_results['fft']['period']
                    col1, col2 = st.columns(2)
                    with col1:
                        plot_map(amp_da, title="FFT æŒ¯å¹…")
                        st.download_button(
                            "â¬‡ï¸ ä¸‹è½½ FFT æŒ¯å¹…",
                            data=dataarray_to_bytes_tif(amp_da),
                            file_name="fft_amplitude.tif",
                            mime="image/tiff",
                            use_container_width=True,
                            help="ä¸‹è½½çš„TIFFæ–‡ä»¶å°†ä¿æŒåŸå§‹åæ ‡ç³»å’Œç©ºé—´å‚è€ƒä¿¡æ¯"
                        )
                    with col2:
                        plot_map(period_da, title="FFT ä¸»å‘¨æœŸ")
                        st.download_button(
                            "â¬‡ï¸ ä¸‹è½½ FFT å‘¨æœŸ",
                            data=dataarray_to_bytes_tif(period_da),
                            file_name="fft_period.tif",
                            mime="image/tiff",
                            use_container_width=True,
                            help="ä¸‹è½½çš„TIFFæ–‡ä»¶å°†ä¿æŒåŸå§‹åæ ‡ç³»å’Œç©ºé—´å‚è€ƒä¿¡æ¯"
                        )

            # STL ç»“æœ
            if 'stl' in st.session_state.analysis_results:
                with st.expander("ğŸ”„ STL åˆ†è§£ç»“æœ", expanded=True):
                    trend_da = st.session_state.analysis_results['stl']['trend']
                    seasonal_da = st.session_state.analysis_results['stl']['seasonal']
                    resid_da = st.session_state.analysis_results['stl']['resid']

                    col1, col2, col3 = st.columns(3)
                    with col1:
                        plot_map(trend_da, title="STL: å¹³å‡è¶‹åŠ¿åˆ†é‡")
                        st.download_button(
                            "â¬‡ï¸ ä¸‹è½½è¶‹åŠ¿åˆ†é‡",
                            data=dataarray_to_bytes_tif(trend_da),
                            file_name="stl_trend_mean.tif",
                            mime="image/tiff",
                            use_container_width=True,
                            help="ä¸‹è½½çš„TIFFæ–‡ä»¶å°†ä¿æŒåŸå§‹åæ ‡ç³»å’Œç©ºé—´å‚è€ƒä¿¡æ¯"
                        )
                    with col2:
                        plot_map(seasonal_da, title="STL: å¹³å‡å­£èŠ‚åˆ†é‡")
                        st.download_button(
                            "â¬‡ï¸ ä¸‹è½½å­£èŠ‚åˆ†é‡",
                            data=dataarray_to_bytes_tif(seasonal_da),
                            file_name="stl_seasonal_mean.tif",
                            mime="image/tiff",
                            use_container_width=True,
                            help="ä¸‹è½½çš„TIFFæ–‡ä»¶å°†ä¿æŒåŸå§‹åæ ‡ç³»å’Œç©ºé—´å‚è€ƒä¿¡æ¯"
                        )
                    with col3:
                        plot_map(resid_da, title="STL: æ®‹å·®æ ‡å‡†å·®")
                        st.download_button(
                            "â¬‡ï¸ ä¸‹è½½æ®‹å·®æ ‡å‡†å·®",
                            data=dataarray_to_bytes_tif(resid_da),
                            file_name="stl_residual_std.tif",
                            mime="image/tiff",
                            use_container_width=True,
                            help="ä¸‹è½½çš„TIFFæ–‡ä»¶å°†ä¿æŒåŸå§‹åæ ‡ç³»å’Œç©ºé—´å‚è€ƒä¿¡æ¯"
                        )

        # ---------------------------
        # äº¤äº’å¼åƒå…ƒåˆ†æ
        # ---------------------------
        st.sidebar.header("ğŸ” åƒå…ƒçº§åˆ†æ")
        with st.expander("ğŸ“ˆ åƒå…ƒæ—¶åºåˆ†æå·¥å…·", expanded=True):
            st.info("ä½¿ç”¨ä¾§è¾¹æ æ»‘æ†é€‰æ‹©ç‰¹å®šåƒå…ƒæŸ¥çœ‹å…¶æ—¶åºç‰¹å¾")

            # æ ¹æ®æ•°æ®é¢‘ç‡è®¾ç½®é»˜è®¤STLå‘¨æœŸ
            pixel_stl_period = 12
            if data_frequency == "å¹´åº¦æ•°æ®":
                pixel_stl_period = 1

            plot_pixel_timeseries(
                data_stack,
                period=st.sidebar.number_input(
                    "STL å‘¨æœŸå‚æ•°",
                    value=pixel_stl_period,
                    min_value=1,
                    max_value=min(24, len(times) // 2),
                    key="pixel_stl_period"
                )
            )

else:
    st.info("ğŸ‘† è¯·åœ¨ä¾§è¾¹æ ä¸Šä¼  GeoTIFF æ–‡ä»¶å¼€å§‹åˆ†æ")

    # ä½¿ç”¨è¯´æ˜
    with st.expander("ğŸ“– ä½¿ç”¨è¯´æ˜", expanded=True):
        st.markdown("""
        ### ğŸ¯ ç³»ç»ŸåŠŸèƒ½
        - **Theilâ€“Senè¶‹åŠ¿åˆ†æ**: è®¡ç®—ç¨³å¥çš„è¶‹åŠ¿æ–œç‡
        - **Mannâ€“Kendallæ£€éªŒ**: æ£€éªŒè¶‹åŠ¿æ˜¾è‘—æ€§  
        - **BFASTçªå˜æ£€æµ‹**: æ£€æµ‹æ—¶é—´åºåˆ—ä¸­çš„çªå˜ç‚¹
        - **FFTå‘¨æœŸåˆ†æ**: åˆ†æå‘¨æœŸæ€§ç‰¹å¾
        - **STLåˆ†è§£**: åˆ†è§£ä¸ºè¶‹åŠ¿ã€å­£èŠ‚å’Œæ®‹å·®åˆ†é‡

        ### ğŸ“ æ•°æ®è¦æ±‚
        - **æ–‡ä»¶æ ¼å¼**: GeoTIFF (.tif, .tiff)
        - **æ—¶é—´ä¿¡æ¯**: æ–‡ä»¶åå¿…é¡»åŒ…å«æ—¶é—´ä¿¡æ¯
        - **å¹´åº¦æ•°æ®å‘½å**: `NDVI_2000.tif`, `NDVI_2001.tif`
        - **æœˆåº¦æ•°æ®å‘½å**: `NDVI_200001.tif`, `NDVI_2000_01.tif`, `NDVI_2000_01_å¾å·.tif`
        - **æ—¥åº¦æ•°æ®å‘½å**: `NDVI_2000_001.tif`, `NDVI_2000_365_å¾å·.tif`
        - **ç©ºé—´èŒƒå›´**: æ‰€æœ‰æ–‡ä»¶å¿…é¡»å…·æœ‰ç›¸åŒçš„ç©ºé—´èŒƒå›´å’Œåˆ†è¾¨ç‡
        - **å»ºè®®æ—¶é—´åºåˆ—é•¿åº¦**: â‰¥3æœŸä»¥è·å¾—æœ‰æ„ä¹‰çš„ç»“æœ

        ### âš¡ ä½¿ç”¨æµç¨‹
        1. åœ¨å·¦ä¾§ä¸Šä¼ å¤šä¸ªGeoTIFFæ–‡ä»¶
        2. ç³»ç»Ÿè‡ªåŠ¨æ£€æµ‹æ•°æ®é¢‘ç‡ï¼ˆå¹´åº¦/æœˆåº¦ï¼‰
        3. é€‰æ‹©è¦è¿è¡Œçš„åˆ†ææ–¹æ³•
        4. ç‚¹å‡»"æ‰§è¡Œé€‰ä¸­åˆ†æ"
        5. æŸ¥çœ‹ç»“æœå¹¶ä¸‹è½½

        ### ğŸ’¡ åˆ†æå»ºè®®
        - **å¹´åº¦æ•°æ®**: é€‚åˆè¶‹åŠ¿åˆ†æå’Œçªå˜æ£€æµ‹
        - **æœˆåº¦æ•°æ®**: é€‚åˆæ‰€æœ‰åˆ†ææ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯STLå’ŒFFTå‘¨æœŸåˆ†æ

        ### â— å¸¸è§é—®é¢˜
        - **ä¸€ä¸ªæ—¶é—´ç‚¹å¤šä¸ªå€¼**: ç¡®ä¿æ–‡ä»¶åä¸­çš„æ—¶é—´ä¿¡æ¯å”¯ä¸€ï¼Œä¸è¦æœ‰é‡å¤çš„æ—¶é—´ç‚¹
        - **æ•°æ®ç»´åº¦é”™è¯¯**: ç¡®ä¿æ‰€æœ‰æ–‡ä»¶éƒ½æ˜¯å•æ³¢æ®µ2Dæ …æ ¼æ•°æ®
        - **æ—¶é—´åæ ‡é”™è¯¯**: æ£€æŸ¥æ–‡ä»¶åä¸­çš„æ—¶é—´æ ¼å¼æ˜¯å¦æ­£ç¡®
        - **åæ ‡ç³»é—®é¢˜**: ç³»ç»Ÿä¼šè‡ªåŠ¨ä¿æŒåŸå§‹æ–‡ä»¶çš„åæ ‡ç³»ä¿¡æ¯
        """)

# é¡µè„š
st.markdown("---")
st.markdown("ğŸ›°ï¸ æ—¶åºé¥æ„Ÿåˆ†æç³»ç»Ÿ | åŸºäº Python + Streamlit æ„å»º")